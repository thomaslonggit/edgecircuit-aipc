#!/usr/bin/env python3
"""
Intel AIPC OpenVINO GenAI API å®¢æˆ·ç«¯ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•è°ƒç”¨æœ¬åœ°éƒ¨ç½²çš„ OpenAI å…¼å®¹ API æœåŠ¡
"""

import json
import requests
import time
from typing import List, Dict

# API æœåŠ¡å™¨é…ç½®
API_BASE_URL = "http://localhost:8000"
API_KEY = "dummy"  # æœ¬åœ°æœåŠ¡æš‚ä¸éœ€è¦çœŸå® API Key


def call_chat_completion(
    messages: List[Dict[str, str]],
    model: str = "qwen2.5-7b-int4",
    temperature: float = 0.2,
    max_tokens: int = 640,
    stream: bool = False
) -> str:
    """è°ƒç”¨èŠå¤©å®Œæˆ API"""
    
    url = f"{API_BASE_URL}/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    
    data = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "stream": stream
    }
    
    if stream:
        # æµå¼è°ƒç”¨
        response = requests.post(url, headers=headers, json=data, stream=True)
        response.raise_for_status()
        
        print("ğŸ”µ åŠ©æ‰‹ï¼š", end='', flush=True)
        collected_content = ""
        
        for line in response.iter_lines():
            if line:
                line_str = line.decode('utf-8')
                if line_str.startswith('data: '):
                    data_str = line_str[6:]  # å»é™¤ 'data: ' å‰ç¼€
                    
                    if data_str == '[DONE]':
                        break
                    
                    try:
                        chunk_data = json.loads(data_str)
                        if chunk_data['choices'][0]['delta'].get('content'):
                            content = chunk_data['choices'][0]['delta']['content']
                            print(content, end='', flush=True)
                            collected_content += content
                    except json.JSONDecodeError:
                        continue
        print()  # æ¢è¡Œ
        return collected_content
    else:
        # éæµå¼è°ƒç”¨
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        
        result = response.json()
        return result['choices'][0]['message']['content']


def list_models() -> List[str]:
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    url = f"{API_BASE_URL}/v1/models"
    response = requests.get(url)
    response.raise_for_status()
    
    result = response.json()
    return [model['id'] for model in result['data']]


def check_health() -> Dict:
    """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
    url = f"{API_BASE_URL}/health"
    response = requests.get(url)
    response.raise_for_status()
    return response.json()


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ Intel AIPC OpenVINO GenAI API å®¢æˆ·ç«¯ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
    try:
        health = check_health()
        print(f"ğŸ¥ æœåŠ¡çŠ¶æ€: {health['status']}")
        print(f"ğŸ“± è®¾å¤‡: {health['device']}")
        print(f"ğŸ“‚ æ¨¡å‹ç›®å½•: {health['model_dir']}")
        print()
    except Exception as e:
        print(f"âŒ æœåŠ¡è¿æ¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿ API æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ: python api_server.py")
        return
    
    # 2. è·å–æ¨¡å‹åˆ—è¡¨
    try:
        models = list_models()
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {models}")
        print()
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return
    
    # 3. å•è½®å¯¹è¯ç¤ºä¾‹ (éæµå¼)
    print("ğŸ”„ å•è½®å¯¹è¯ç¤ºä¾‹ (éæµå¼)")
    print("-" * 30)
    
    messages = [
        {"role": "user", "content": "ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
    ]
    
    try:
        start_time = time.time()
        response = call_chat_completion(messages, stream=False)
        end_time = time.time()
        
        print(f"ğŸŸ¢ ç”¨æˆ·ï¼š{messages[0]['content']}")
        print(f"ğŸ”µ åŠ©æ‰‹ï¼š{response}")
        print(f"â±ï¸  è€—æ—¶ï¼š{end_time - start_time:.2f}ç§’")
        print()
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return
    
    # 4. å¤šè½®å¯¹è¯ç¤ºä¾‹ (æµå¼)
    print("ğŸ”„ å¤šè½®å¯¹è¯ç¤ºä¾‹ (æµå¼)")
    print("-" * 30)
    
    conversation = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´åœ°å›ç­”é—®é¢˜ã€‚"},
        {"role": "user", "content": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"},
    ]
    
    try:
        print(f"ğŸŸ¢ ç”¨æˆ·ï¼š{conversation[1]['content']}")
        call_chat_completion(conversation, stream=True, temperature=0.7, max_tokens=200)
        print()
    except Exception as e:
        print(f"âŒ æµå¼è¯·æ±‚å¤±è´¥: {e}")
    
    # 5. äº¤äº’å¼å¯¹è¯
    print("ğŸ’¬ äº¤äº’å¼å¯¹è¯ (è¾“å…¥ 'quit' é€€å‡º)")
    print("-" * 30)
    
    chat_history = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚"}
    ]
    
    while True:
        try:
            user_input = input("\nğŸŸ¢ ä½ ï¼š").strip()
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            chat_history.append({"role": "user", "content": user_input})
            
            # æµå¼å“åº”å¹¶æ”¶é›†åŠ©æ‰‹çš„å›å¤
            assistant_response = call_chat_completion(chat_history, stream=True, temperature=0.3)
            
            # å°†åŠ©æ‰‹çš„å›å¤æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
            if assistant_response:
                chat_history.append({"role": "assistant", "content": assistant_response})
            
        except (EOFError, KeyboardInterrupt):
            break
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
    
    print("\nğŸ‘‹ å†è§ï¼")


if __name__ == "__main__":
    main() 